name: gpu-smoke
on:
  workflow_dispatch: {}
  push:
    branches: [ main ]

jobs:
  smoke:
    runs-on: [self-hosted, gpu]
    timeout-minutes: 30
    steps:
      - uses: actions/checkout@v4
      - name: Show GPU
        run: |
          nvidia-smi || true
      - name: Torch sanity
        run: |
          python - <<'PY'
          import torch
          print("CUDA available:", torch.cuda.is_available())
          print("device_count:", torch.cuda.device_count())
          if torch.cuda.is_available():
              print("device_0:", torch.cuda.get_device_name(0))
          PY
