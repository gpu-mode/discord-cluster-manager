name: gpu-smoke
on:
  push:
    branches: [ nvidia-gpu-runners ]
  workflow_dispatch: {}
jobs:
  smoke:
    runs-on: [self-hosted, gpu]
    steps:
      - uses: actions/checkout@v4
      - run: nvidia-smi || true
      - run: |
          python - <<'PY'
          import torch
          print("cuda?", torch.cuda.is_available(), "count:", torch.cuda.device_count())
          if torch.cuda.is_available():
              print("name:", torch.cuda.get_device_name(0))
          PY
